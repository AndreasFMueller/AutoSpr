%
% grammatik.tex -- Grammatik
%
% (c) 2019 Prof Dr Andreas Müller, Hochschule Rapperswil
%
\section{Kontextfreie Sprachen}
\rhead{Kontextfreie Sprachen}
\subsection{Kontextfreie Grammatiken}
Reguläre Sprachen werden dadurch definiert, dass die Zeichen
eines Wortes von links nach rechts gelesen werden, und nach jedem
Zeichen entschieden werden kann, ob das Wort akzeptabel ist.
Der Fokus liegt also auf der Analyse des Strings, und genau dies
macht das Überprüfen der korrekten Schachtelung von Klammern
schwierig. 

\index{Ausdr\ücke!arithmetische}%
Für Klammern ist man sich jedoch meistens eine andere Vorgehensweise
gewohnt. Wenn man arithmetische Ausdrücke aufbaut, sagt man zum
Beispiel: ``Wenn man die Summe $a+b$ mit $c$ multiplizeren will,
dann {\em muss man $a+b$ in Klammern setzen}''.
Klammern werden also immer paarweise gesetzt, und man baut den
Ausdruck sozusagen von innen nach aussen auf.

Wir möchten diese Idee ein Stück weit formalisieren. Das Ziel ist,
Wörter aus den Zeichen {\tt (} und {\tt )} aufzubauen, die korrekte
Klammerausdrücke sind. Dazu können wir bereits bekannte korrekte
Klammerausdrücke aneinanderhängen, oder wir können einen bereits
bekannten korrekten Ausdruck ``einklammern''. Schreiben wir $A$
für einen Klammerausdruck, bedeutet das, dass wir $A$ gemäss
folgender Regeln umformen können:
\begin{align*}
A&\to AA\\
A&\to {\tt (}A{\tt )}
\end{align*}
Dabei ist auf der rechten Seite der ersten Regel gemeint, dass wir zwei beliebige
Ausdrücke nehmen können, sie müssen nicht identisch sein. Allerdings
fehlt in diesen Regeln noch ein Anfang, bis jetzt können wir überhaupt
keine Wörter produzieren. Dazu nehmen wir noch eine Regel $A\to\varepsilon$
hinzu, die besagt, dass das leere Wort auch ein akzeptabler
Klammerausdruck ist. Die Regeln
\begin{align}
A&\to\varepsilon       \label{regeln-beispiel-1}\\
A&\to AA               \label{regeln-beispiel-2}\\
A&\to {\tt (}A{\tt )}  \label{regeln-beispiel-3}
\end{align}
erzeugen in diesem Sinne alle korrekt geschachtelten Klammerausdrücke.

Der Buchstabe $A$ steht offenbar nicht immer für das gleiche, 
er ist Platzhalter für einen korrekten Klammerausdruck. Wir nennen
$A$ eine Variable.
Dagegen stehen die Zeichen {\tt (} und {\tt )} nur für sich selbst, sie
können nicht weiter ersetzt werden, sie heissen Terminalsymbole.

Damit sind wir bereit für die formale Definition einer kontextfreien
Grammatik.
\begin{definition}
\index{Grammatik!kontextfreie}%
Eine kontextfreie Grammatik ist ein Quadrupel $(V,\Sigma,R,S)$ mit
\begin{compactenum}
\index{Variable}%
\item $V$ ist eine endliche Menge von Variablen.
\index{Terminalsymbol}%
\item $\Sigma$ ist eine endliche Menge von Zeichen, disjunkt zu $V$,
auch genannt die Terminalsymbole.
\item $R$ ist eine Menge von Regeln, eine Regel besteht aus einer
Variable und einer Kette von Variablen und Terminalsymbolen, geschrieben
in der Form $A\to BC{\tt x}$, wobei rechts eine beliebige Folge von
Variablen (in diesem Fall $A$ und $B$) und Terminalsymbolen (in diesem Fall
\texttt{x}) stehen kann.
\index{Regel!einer kontextfreien Grammatik}%
\item $S\in V$ ist die Startvariable.
\index{Startvariable}%
\end{compactenum}
\end{definition}
Im Beispiel ist $V=\{A\}$, $\Sigma=\{{\tt (},{\tt )}\}$, $S=A$ und
$R$ enthält genau drei Regeln (\ref{regeln-beispiel-1}) bis
(\ref{regeln-beispiel-3}).

Zur Abkürzung erlauben wir, Regeln mit der gleichen Variablen
auf der linken Seite des Pfeils mit einem Vertikalstrich als
Verknüpfungszeichen auf der rechten Seite zu schreiben, zu lesen
als ``oder'':
\[
A \to \varepsilon\;|\; AA\;|\; {\tt (}A{\tt )}.
\]

Der Name ``kontextfrei'' rührt daher, dass es bei der Anwendung
der Regeln nicht auf den Kontext ankommt, in dem eine Variable
auf der linken Seite des Pfeils~$\rightarrow$ vorkommt. Regeln der
Form 
\[
{\tt a}A\to AA, \qquad {\tt bA}\to BB,
\]
sogenannte kontextsensitive Regeln,
\index{kontextsensitiv}%
würden dagegen ausdrücken, dass die Umwandlung der Variablen $A$
unterschiedlich zu erfolgen hat, wenn ihr verschiedene Zeichen
vorangehen. In diesem Fall käme es auf den Kontext an. Solche
Regeln sollen jedoch nicht zugelassen sein.

\subsection{Kontextfreie Sprachen}
Eine Grammatik erzeugt eine Sprache auf die folgende Weise.
Auf die Startvariable werden beliebige Regeln angewendet,
bis keine Variablen mehr vorhanden sind, jetzt steht nur noch
eine Kette von Terminalsymbolen da. Dies wollen wir wie folgt
formalisieren.

\begin{definition}
\index{Regel!erzeugtes Wort}%
\index{Ableitung}%
Falls $A\to w$ eine Regel einer Grammatik $G$ ist, sagt man
dass die Regel aus $uAv$ den String $uwv$ erzeugt,
geschrieben $uAv\Rightarrow uwv$. Man sagt, $v$ lässt sich aus
$u$ ableiten, wenn es eine Folge $u_1,\dots,u_n$ gibt mit
\[
u\Rightarrow u_1\Rightarrow u_2\Rightarrow\dots\Rightarrow u_n\Rightarrow v,
\]
auch geschrieben als $u\overset{*}{\Rightarrow} v$
\end{definition}

\begin{beispiel}
Als Beispiel sei das Wort \texttt{(()())} aus der Grammatik
(\ref{regeln-beispiel-1})
bis
(\ref{regeln-beispiel-2})
für die Klammerausdrücke abgeleitet:
\begin{align*}
A
&\xrightarrow{\text{(\ref{regeln-beispiel-3})}} \texttt{(} A \texttt{)}
 \xrightarrow{\text{(\ref{regeln-beispiel-2})}} \texttt{(} AA \texttt{)}
 \xrightarrow{\text{(\ref{regeln-beispiel-3})}} \texttt{((} A\texttt{)}A \texttt{)}
 \xrightarrow{\text{(\ref{regeln-beispiel-3})}} \texttt{((} A\texttt{)(}A \texttt{))}
 \xrightarrow{\text{(\ref{regeln-beispiel-1})}} \texttt{((} \texttt{)(}A \texttt{))}
 \xrightarrow{\text{(\ref{regeln-beispiel-1})}} \texttt{((} \texttt{)(} \texttt{))}
\end{align*}
Die Reihenfolge der Regelanwendung ist nicht eindeutig.
\end{beispiel}

\begin{definition}
\index{Sprache!von einer CFG erzeugte}%
Die Menge aller Wörter, die von einer kontextfreien Grammatik 
$G$ erzeugt werden können wir mit
\[
L(G)=\{w\in\Sigma^*\;|\; S\overset{*}{\Rightarrow} w\}
\]
bezeichnen.
\end{definition}

Zu jeder kontextfreien Grammatik gibt es also eine Sprache bestehend aus
den von der Grammatik produzierten Wörtern.
Die kontextfreien Sprachen sind die Sprachen, die auf diese Weise entstehen.

\begin{definition}
\index{kontextfreie Sprache}%
\index{Sprache!kontextfrei}%
Eine Sprache $L$ heisst {\em kontextfrei}, wenn es eine kontextfreie
Grammatik $G$ gibt derart, dass $L=L(G)$.
\end{definition}

\subsection{Beispiele}
\subsubsection{Natürliche Zahlen}
Natürliche Zahlen sind Wörter über dem Alphabet $\Sigma=\{
{\tt 0},
{\tt 1},
{\tt 2},
{\tt 3},
{\tt 4},
{\tt 5},
{\tt 6},
{\tt 7},
{\tt 8},
{\tt 9}\}$, welche von den Grammatikregeln
\begin{align*}
N&\to Z\\
 &\to NZ\\
Z&\to {\tt 0}\;|\;\dots \;|\;{\tt 9}
\end{align*}
erzeugt werden.

Diese Grammatik hat aber den Mangel, dass sie auch Zahlen
mit führenden Nullen erlaubt.
Diese könnten dadurch entfernt
werden, dass wir eine weitere Variable für zulässige
Anfangsziffern einführen.
Die Bezeichnung der Variablen mit einzelnen Buchstaben wird jetzt
bereits etwas unübersichtlich, wir schreiben die Grammatik daher neu
so:
\begin{align*}
\textsl{zahl}           &\to\textsl{nichtnullziffer}\; \textsl{ziffernfolge} \\
                        &\to\textsl{ziffer}\\
\textsl{ziffernfolge}   &\to \textsl{ziffernfolge}\; \textsl{ziffer}\\
                        &\to \textsl{ziffer}\\
\textsl{ziffer}         &\to \texttt{0}\; |\; \textsl{nichtnullziffer}\\
\textsl{nichtnullziffer}&\to \texttt{1}\;|\;\texttt{2}\;|\;\dots\;|\;\texttt{9}
\end{align*}
Damit ist auch gleich der Fall einer einzelnen Null abgehandelt, denn eine
solche ist ja eine \textsl{ziffer}, und eine \textsl{zahl} kann auch eine
einzelne Ziffer sein.

\subsubsection{Einfache arithmetische Ausdrücke}
\index{Ausdr\ücke!arithmetische}%
\index{expression-term-factor Grammatik}%
Auch arithemtische Ausdrücke können mit einer
Grammatik erzeugt werden. Da die Zahl der Variablen schnell grösser
wird, werden wir im Folgenden auch länger Variablennamen zulassen.
Als Alphabet verwenden wir
$\Sigma=\{{\tt 0},\dots,{\tt 9},{\tt +},{\tt *},{\tt (}, {\tt )}\}$.
Die Startvariable drückt aus, was erzeugt werden soll, in diesem Fall
ein Ausdruck, also nennen wir sie \textsl{expression}.  Folgende Grammatik
erzeugt die arithmetischen Ausdrücke:
\begin{align*}
\textsl{expression} &\to \textsl{expression}\;{\tt +}\;\textsl{term}\\
                    &\to \textsl{term}\\
\textsl{term}       &\to \textsl{term}\;{\tt *}\;\textsl{factor}\\
                    &\to \textsl{factor}\\
\textsl{factor}     &\to {\tt (}\textsl{expression}{\tt )}\\
                    &\to N\\
N                   &\to Z\\
                    &\to NZ\\
Z                   &\to {\tt 0}\;|\;\dots \;|\;{\tt 9}
\end{align*}

\subsubsection{Eine nicht reguläre Sprache}
Die Sprache $\{{\tt 0}^n{\tt 1}^n\;|\;n\in\mathbb N\}$ wurde bereits
früher als nicht regulär erkannt. Sie wird aber von der 
Grammatik $G=(\{S\}, \{{\tt 0},{\tt 1}\}, R, S)$ erzeugt
mit den Regeln
\begin{align*}
S&\rightarrow \varepsilon\\
&\rightarrow {\tt 0}S{\tt 1}
\end{align*}

\subsection{Reguläre Operationen\label{sect:cfg-regulaer}}
In diesem Abschnitt beweisen wir, dass reguläre Sprachen auch
kontextfrei sind. Dazu ist zu zeigen, dass
zu jedem regulären Ausdruck eine kontextfreie Grammatik existiert,
die die Sprache erzeugt.

\begin{satz}[Vereinigung]
\label{satz:cfg-union}
\index{Vereinigung}%
Seien $L_1$ und $L_2$ kontextfreie Sprachen über $\Sigma$,
dann ist auch $L_1\cup L_2$ kontextfrei.
\end{satz}

\begin{proof}[Beweis]
Weil $L_i$ kontextfrei sind,  gibt es Grammatiken $G_1$ und $G_2$,
die $L_1$ bzw.~$L_2$ erzeugen. Wir dürfen sogar annehmen, dass
beide Grammatiken keine
gemeinsamen Variablen haben, dass also $V_1$ und $V_2$ 
disjunkt sind. Wir konstruieren jetzt eine neue Grammatik
$G=(V_1\cup V_2\cup\{S\}, \Sigma, R, S)$ mit einem neuen
Startzustand $S$. Die Regelmenge $R$ besteht einerseits aus
den Regeln in $G_1$ und $G_2$ und andererseits aus der neuen
Regel
\[
S\to S_1 | S_2.
\]
Insgesamt ist also
\[
R=R_1\cup R_2\cup \{S\to S_1, S\to S_2\}.
\]
Die Wörter von $L_1$ werden erzeugt, wenn man $S\to S_1$ als
erste Regel anwendet, die Wörter von $L_2$ jedoch, wenn 
man $S\to S_2$ verwendet. Die Regeln können nicht ``gemischt''
angewendet werden, weil $V_1\cap V_2=\emptyset$.
\end{proof}

\begin{satz}[Verkettung]
\label{satz:cfg-verkettung}
\index{Verkettung}%
Sind $L_1$ und $L_2$ kontextfreie Sprachen, dann ist auch $L_1L_2$
kontextfrei.
\end{satz}

\begin{proof}[Beweis]
Seien wieder $G_i$ die Grammatiken, die $L_i$ erzeugen, mit disjunkten
Variablenmengen $V_1\cap V_2=\emptyset$. Dann erzeugt die Grammatik
$G=(V_1\cup V_2\cup\{S\},\Sigma, R,S)$ mit dem neuen Startzustand
und den Regeln
\[
R=R_1\cup R_2\cup \{S\to S_1S_2\}
\]
die Sprache $L_1L_2$.
\end{proof}

\begin{satz}[$*$-Operation]
\index{*-Operation@$*$-Operation}%
\label{satz:cfg-star}
Ist $L$ kontextfrei, dann auch $L^*$.
\end{satz}

\begin{proof}[Beweis]
Sei $G=(V,\Sigma,R,S)$ die Grammatik, die $L$ erzeugt. Dann erzeugt die
Grammatik
\[
G^*=(V\cup \{S_0\}, \Sigma, R_0, S_0)
\]
mit
\[
R_0=R\cup \{ S_0\to S_0S, S_0\to\varepsilon \}
\]
die Sprache $L^*$.
\end{proof}

\begin{satz} Sei $L$ eine reguläre Sprache, dann gibt es eine
kontextfreie Grammatik $G$ mit $L(G)=L$.
\end{satz}

\begin{proof}[Beweis]
Da reguläre Sprachen mit regulären Operationen aus einfacheren
Sprachen aufgebaut werden können, ist nur zu zeigen, dass die
Konstruktionen, die mit regulären Operationen möglich sind,
auch durch Produktionsregeln einer Grammatik ausgedrückt werden
können. 
\begin{enumerate}
\item Leere Sprache: Die leere Sprache ist regulär. Sie wird auch 
von der Grammatik mit $R=\emptyset$ erzeugt, also ist sie auch
kontextfrei.
\item Ein einzelnes Zeichen: $L=\{{\tt a}\}$. Die Sprache $L$ wird von
der Grammatik $G=(\{S\}, \{{\tt a}\}, \{S\to{\tt a}\}, S)$
erzeugt.
\item Alle Sprachen, die sich aus den eben genannten durch reguläre
Operationen konstruieren lassen, sind ebenfalls kontextfrei. Da
dies für alle regulären Sprachen zutrifft folgt, dass alle
regulären Sprachen kontextfrei sind.
\end{enumerate}
\end{proof}

Der Satz zeigt, dass die kontextfreien Sprachen eine echte
Obermenge der regulären Sprachen sind:
\begin{center}
%\includegraphics[width=0.5\hsize]{images/lang-1}
\includegraphics{images/lang-1}
\end{center}
Wir werden später zeigen, dass kontextfreie Sprachen auch durch
die Existenz eines Stackautomaten charakterisiert werden können,
der diese Sprachen akzeptiert. Dann wird sich zeigen, dass 
die regulären Sprachen diejenigen kontextfreien Sprachen sind,
für deren Analyse der Stack gar nicht benötigt wird.

\subsection{Parse Tree}
\index{parse tree}%
\index{Ableitungsbaum}%
Der Ableitungsbaum eines Wortes einer kontextfreien Sprache
ist eine Darstellung der verwendeten Produktionsregeln in Baum-Struktur.
\index{Ausdr\ücke!arithmetische}%
Die Grammatik für arithmetische Ausdrücke produziert zum Beispiel
den Ausdruck {\tt 7 * (3 + 5)}.
Die dabei verwendeten Regeln können in Baumform wie in
Abbildung \ref{etf-parse-tree} dargestellt werden.

\begin{figure}
{
\small
\[
\xymatrix{
	&\textsl{expression} \ar[d]
\\
	&\textsl{term} \ar[dl] \ar[d] \ar[drrr]
\\
\textsl{term}\ar[dddd]
	&{\tt *}\ar[ddddddd]
		&
			&
				&\textsl{factor}\ar@/_80pt/[dddddddll]\ar[d]\ar@/^40pt/[dddddddrr]
					&
						&
\\
	&
		&
			&
				&\textsl{expression}\ar[dl]\ar[dddddd]\ar[ddr]
					&
\\
	&
		&
			&\textsl{expression}\ar[d]
				&
					&
						&
\\
	&
		&
			&\textsl{term}\ar[d]
				&
					&\textsl{term}\ar[d]
						&
\\
\textsl{factor}\ar[d]
	&
		&
			&\textsl{factor}\ar[d]
				&
					&\textsl{factor}\ar[d]
						&
\\
N\ar[d]
	&
		&
			&N\ar[d]
				&
					&N\ar[d]
						&
\\
Z\ar[d]
	&
		&
			&Z\ar[d]
				&
					&Z\ar[d]
						&
\\
{\tt 7}
	&{\tt *}
		&{\tt (}
			&{\tt 3}
				&{\tt +}
					&{\tt 5}
						&{\tt )}
}
\]
}
\caption{Parse-Tree des Ausdrucks \texttt{7 * ( 3 + 5 )} in der
Expression-Term-Factor-Grammatik.
\label{etf-parse-tree}}
\end{figure}

Offenbar spielt es keine Rolle, ob erst die Regelanwendungen
im linken Teil des Baumes geschehen, oder die Regelanwendungen im
rechten Teil. Zwei Ableitungen können daher als gleich angesehen
werden, wenn sich die Ableitungsbäume nicht unterscheiden.

\begin{definition}
\index{Aquivalenz@Äquivalenz!von Ableitungen}%
Zwei Ableitungen eines Wortes $w$ einer kontextfreien Sprache $L(G)$
heissen äquivalent, wenn sie den gleichen Ableitungsbaum haben.
Hat eine Sprache Wörter mit verschiedenen Ableitungen, heisst
sie mehrdeutig (engl.~ambiguous).
\end{definition}

Von besonderem praktischem Interesse sind Grammatiken, in denen
Ableitungen immer eindeutig sind. Die
\index{expression-term-factor Grammatik}%
{\tt expression}-{\tt term}-{\tt factor}-Grammatik für einfache
arithmetische Ausdrücke erfüllt diese Bedingung. 
Ein Beispiel für eine zweideutige Grammatik ist
\[
G=(\{S\}, \{\texttt{0},\texttt{1}\}, \{S\to \texttt{0}S\texttt{1}|\texttt{1}S\texttt{0}|SS|\varepsilon\}, S).
\]
$G$ erzeugt die Sprache
$\{w\in \{\texttt{0},\texttt{1}\}^*\,|\, |w|_{\texttt{0}} = |w|_\texttt{1}\}$, aber das Wort
$\texttt{001011}$ hat mindestens zwei verschiedene Ableitungen:
\[
\xymatrix{
&&&S\ar@/_10pt/[dddddlll]\ar[d]\ar@/^30pt/[dddddrrrr]
\\
&&&S\ar[dl]\ar[drr]
\\
 &&S\ar[dddl]\ar[d]\ar[dddr]&&&S\ar[dddl]\ar[d]\ar[dddr]&&
\\
&&S\ar[d]&&&S\ar[d]&&
\\
 & &\varepsilon& & &\varepsilon& & 
\\
\texttt{0}&\texttt{0}& &\texttt{1}&\texttt{0}& &\texttt{1}&\texttt{1}
}
\]
oder
\[
\xymatrix{
&&&S\ar@/_/[dddddlll]\ar[d]\ar@/^/[dddddrrr]
\\
&&&S\ar@/_/[ddddll]\ar[d]\ar@/^/[ddddrr]&&&
\\
&&&S\ar@/_/[dddl]\ar[d]\ar@/^/[dddr]&&&
\\
&&&S\ar[d]&&&
\\
&&&\varepsilon&&&
\\
\texttt{0}&\texttt{0}&\texttt{1}&&\texttt{0}&\texttt{1}&\texttt{1}
}
\]


\subsection{Chomsky Normalform}
%Die Regeln einer Grammatik unterliegen kaum Einschränkungen, abgesehen
%von der Forderung, dass sie kontextfrei sind.
%Zum Beispiel ist zulässig, dass es beliebig viele Regeln der Form
%$A\to\varepsilon$ geben kann.
%Solche Regeln ermöglichen, ein einmal erzeugtes Wort wieder zu verkürzen.
%Gäbe es keine solchen Regeln, könnte ein Wort nur länger werden und damit
%liesse sich besser abschätzen, wie lange die Ableitung eines Wortes
%überhaupt werden kann.

%Umgekehrt können Regeln mit sehr vielen Variablen oder Terminalsymbolen
%auf der rechten Seite ein Wort in sehr wenigen Ableitungsschritten
%stark aufblasen, was wieder eie Abschätzung der Anzahl der nötigen
%Ableitungsschritte erschwert.
%Regeln der Form $A\to B$ können zu Umwandlungsschleifen führen,
%die zu beliebig langen Ableitungen führen könnten.
%Um solchen Schwierigkeiten aus dem Weg zu gehen, sollen die 
%Regeln etwas eingeschränkt werden.

Reduziert man die Grammatik für Klammerausdrücke auf die beiden Regeln
\begin{equation}
\begin{aligned}
A&\to AA
\\
 &\to\varepsilon,
\end{aligned}
\label{cfg:unendlichegrammatik}
\end{equation}
dann kann man damit nur noch das leere Wort erzeugen.
Zwischenzeitlich kann man aber mit der ersten Regel beliebig lange 
Folgen von $A$s herstellen, die man dann mit der zweiten Regel ins
leere Wort verwandeln kann.
Es gibt insbesondere unendlich viele verschiedene Ableitungen für
das leere Wort.
Für die Grammatik~\eqref{cfg:unendlichegrammatik} lassen sich also
keine Aussagen über die Grösse eines Parsetrees machen.
Dieses pathologische Verhalten kann auch bei komplexeren Grammatiken
auftreten, wenn sie Regeln wie in \eqref{cfg:unendlichegrammatik}
enthalten.

Wie könnte man dies vermeiden? 
\begin{itemize}
\item
$\varepsilon$-Regeln besagen, dass diese Variable optional ist.
Man braucht man eigentlich nur, wenn das leere Wort erzeugen will.
Dies kann man aber auch mit der Regel $S\to\varepsilon$ erreichen.
Andere $\varepsilon$-Regeln müssen daher vermieden werden.
\item
Das Problem wird mitverursacht durch die Möglichkeit, Variablen mit 
$\varepsilon$-Regeln zum Verschwinden zu bringen.
Da man die Regel $S\to\varepsilon$ nicht vermeiden kann, muss verlangt
werden, dass die Startvariable $S$ auf der rechten Seite keiner Regel
vorkommt.
\item
Regeln der Form $A\to B$ erlauben die Ableitung zu verlängern, ohne
dass die Wortlänge zunimmt.
Solche sogenannten unit rules sind daher ebenfalls zu vermeiden.
\end{itemize}

Bei den regulären Sprachen war der Algorithmus zur Reduktion
auf den minimalen Automaten die Voraussetzung, Automaten vergleichen
zu können. Eine ähnliche Normalform wünscht man sich auch für
Grammatiken.

Aus diesen Gründen definiert man die folgende Standardform einer Grammatik
\begin{definition}
\label{definition:cnf}
\index{Chomsky Normalform}%
Eine kontextfreie Grammatik  ist in Chomsky Normalform, wenn
jede Regel von der Form
\begin{align*}
A&\to BC\qquad\text{oder}\\
A&\to a
\end{align*}
ist, wobei $A\in V$, $a\in\Sigma$ und $B, C\in V\setminus\{S\}$.
Zusätzlich ist die Regel $S\to\varepsilon$ erlaubt. 
\end{definition}

Bei einer Grammatik in Chomsky Normalform kann man sofort abschätzen,
wieviele Regelanwendungen notwendig sind, um ein gegebenes Wort
zu erzeugen. Wendet man eine der Regeln $A\to BC$ an, wird das
Wort verlängert. Dies kann nicht mehr rückgängig gemacht
werden, weil dazu eine Regel notwendig wäre, die eine Variable
in das leere Wort umwandelt. Die Regel $S\to\varepsilon$ ist aber
die einzige erlaubte derartige Regel, aber sie kann nie angewendet
werden weil $B$ und $C$ nicht $S$ sein können. Es werden also
höchstens $|w|-1$ Anwendungen von Regeln $A\to BC$ benötig, und dann
nochmals $|w|$ Anwendungen von Regeln $A\to a$, welche die Variablen
in Terminalsymbole umwandeln. 

Eine Grammatik kann aus folgenden Gründen nicht der Chomsky Normalform
entsprechen:
\begin{enumerate}
\item Die Startvariable $S$ könnte auf der rechten Seite einer
Regel vorkommen.
\item Eine $\varepsilon$-Regel $A\to\varepsilon$ mit einer Variablen
$A$, die nicht die Startvariable ist.
\index{unit rule}%
\index{Einheits-Regeln}%
\item Regeln der Form $A\to B$, sogenannte unit rules oder Einheits-Regeln.
\item Regeln der Form $A\to u_1u_2\dots u_n$, mit $n>2$, wobei
die $u_i$ sowohl andere Variablen wie auch Terminalsymbole sein 
können.
\end{enumerate}
Es ist möglich, alle diese Defekte zu ``reparieren'', und jede
Grammatik in Chomsky Normalform zu überführen, wie der folgende Satz
zeigt.

\begin{satz}
\label{satz:cnf}
Eine kontextfreie Sprache wird erzeugt von einer Grammatik
in Chomsky Normalform.
\end{satz}

\begin{proof}[Beweis]
Eine kontextfreie Sprache $L$ wird von einer kontextfreien Grammatik
$G$ akzeptiert. Es ist zu zeigen, dass diese Grammatik in
äquivalente Chomsky Normalform gebracht werden kann.
Weiter oben haben wir eine Liste
möglicher Defekte zusammengestellt, die eine Grammatik davon abhalten,
Chomsky Normalform zu haben. Um Chomsky Normalform zu erreichen,
müssen also genau diese Defekte behoben werden.
Dazu sind folgende Schritte notwendig
\begin{enumerate}
\item Damit die Startvariable nicht mehr auf der rechten Seite auftreten
kann, wird eine neue Startvariable $S_0$ hinzugefügt, sowie eine
neue Regel
$S_0\to S$, wobei $S$ die ursprüngliche Startvariable war.
\item Entfernung aller $\varepsilon$-Regeln. Solche Regeln erlauben,
eine Variable ``wegzulassen''. Für jede Regel, die auf der rechten
Seite eine solche Variable enthält, fügen wir eine zusätzliche
Regel hinzu, bei der die $\varepsilon$-Regel auf der rechten Seite
angwendet worden ist, d.\,h.~die Variable auf der rechten Seite weggelassen
wurde.  Aus
\[
\left.
\begin{aligned}
A&\to\varepsilon\\
B&\to AC\\
\end{aligned}
\right\}
\qquad
\Rightarrow
\qquad
\left\{
\begin{aligned}
B&\to AC\\
&\to C\\
\end{aligned}
\right.
\]
Die $\varepsilon$-Regeln werden damit unnötig, mit der einzig
möglichen Ausnahme einer Regel $S_0\to\varepsilon$, die nicht
eliminiert werden kann, weil $S_0$ nicht auf der rechten Seite
vorkommt.
\item Entfernung von sogenannten ``unit rules'' oder Einheits-Regeln:
Regeln mit einer einzelnen Variablen auf der rechten Seite, also
der Form $A\to B$ können dadurch eliminert werden, dass man
sie in jeder Regel anwendet, die $B$ auf der linken Seite enthält.
\[
\left.
\begin{aligned}
A&\to B\\
B&\to CD
\end{aligned}
\right\}
\qquad\Rightarrow\qquad
\left\{
\begin{aligned}
A&\to CD\\
B&\to CD
\end{aligned}
\right.
\]
Wieder muss man die ursprüngliche Regel $B\to CD$ natürlich
behalten, denn $B$ könnte ja auch auf andere Art erhalten worden
sein als mit der Regel $A\to B$.
\item Verkettungen: Eine Regel der Form $A\to u_1\dots u_n$ kann mit
Hilfe neuer Variablen $A_1,\dots,A_{n-2}$ in folgende Regeln abgebildet
werden
\begin{align*}
A&\to u_1A_1\\
A_1&\to u_2A_2\\
A_2&\to u_3A_3\\
&\vdots\\
A_{n-2}&\to u_{n-1}u_n
\end{align*}
Falls $u_i$ ein Terminalsymbol ist, ersetzen wir $u_i$ in obigen
Regeln durch eine neue Variable $U_i$ und fügen die Regel
$U_i\to u_i$ hinzu. Damit erhalten alle hinzugefügten Regeln
Chomsky Normalform.
\end{enumerate}
Die so konstruierte Grammatik hat Chomsky Normalform und erzeugt die
gleiche Sprache.
\end{proof}

\subsubsection{Beispiel}
Man bringe die Grammatik über dem Alphabet $\Sigma=\{{\tt a},{\tt b}\}$
mit den Regeln
\begin{align*}
S&\to ASA\;|\; {\tt a}B\\
A&\to B\;|\; S\\
B&\to{\tt b}\;|\; \varepsilon
\end{align*}
in Chomsky Normalform.

\begin{enumerate}
% 1. Schritt: neue Startvariable
\item Neue Startvariable hinzufügen:
\begin{align*}
S_0&\to S\\
S&\to ASA\;|\; {\tt a}B\\
A&\to B\;|\; S\\
B&\to{\tt b}\;|\; \varepsilon
\end{align*}
% 2. Schritt: epsilon-Uebergaenge
\item $\varepsilon$-Regeln entfernen: Die einzige $\varepsilon$-Regel
ist $B\to\varepsilon$, d.\,h.~zu jeder Regel mit $B$ auf der rechten
Seite gibt es auch eine Regel, in welcher auf der rechten Seite das $B$
weggelassen wurde:
\begin{align*}
S_0&\to S\\
S&\to ASA\;|\; {\tt a}B\;|\;{\tt a}\\
A&\to B \;|\; \varepsilon \;|\; S\\
B&\to{\tt b}
\end{align*}
In diesem Schritt ist eine neue $\varepsilon$-Regel entstanden, die
man auch noch gleichartig behandeln muss:
\begin{align*}
S_0&\to S\\
S&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
A&\to B \;|\; S\\
B&\to{\tt b}
\end{align*}
% 3. Schrit: Unit rules
\item Einheits-Regeln (unit rules) sind $A\to B$, $A\to S$ und $S_0\to S$,
die alle angewendet werden müssen.
Zuerst $A\to B$:
\begin{align*}
S_0&\to S\\
S&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
A&\to S\\
B&\to{\tt b}\\
A&\to{\tt b}
\end{align*}
Im Folgenden fassen wir die von $A$ ausgehenden Regeln wieder auf
einer Zeile zusammen.
Als nächstes wenden wir $A\to S$ an, aus $A$ lassen sich die gleichen
Wörter produzieren wie aus $S$, aber zusätzlich noch das $\texttt{b}$:
\begin{align*}
S_0&\to S\\
S&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
A&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\;|\;{\tt b}\\
B&\to{\tt b}
\end{align*}
Und zum Schluss $S_0\to S$
\begin{align*}
S_0&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
S&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
A&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\;|\;{\tt b}\\
B&\to{\tt b}
\end{align*}
%Wobei wir die von $A$ ausgehenden Regeln zusammenfassen können:
%\begin{align*}
%S_0&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
%S&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
%A&\to ASA \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\;|\; {\tt b}\\
%B&\to{\tt b}
%\end{align*}
% 4. Schritt
\item Längere Verkettungen gibt es nur bei $S\to ASA$, wir führen
also eine zusätzliche Variable $A_1$ und ersetzen $S\to ASA$ durch
die Regeln $S\to AA_1$ und $A_1\to SA$:
\begin{align*}
S_0&\to AA_1 \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
S&\to AA_1 \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a}\\
A&\to AA_1 \;|\; AS \;|\; SA \;|\; {\tt a}B\;|\;{\tt a} \;|\; {\tt b}\\
A_1&\to SA\\
B&\to{\tt b}
\end{align*}
Bleiben nur noch die Regeln $S_0\to{\tt a}B$, $S\to{\tt a}B$ und
$A\to{\tt a}B$.
Dazu wird eine weitere Variable $U$ hinzugefügt, die zusammen mit
der Regel $U\to{\tt a}$ das Terminalsymbol {\tt a} in den genannten
Regeln ersetzen kann:
\begin{align*}
S_0&\to AA_1 \;|\; AS \;|\; SA \;|\; UB\;|\;{\tt a}\\
S&\to AA_1 \;|\; AS \;|\; SA \;|\; UB\;|\;{\tt a}\\
A&\to AA_1 \;|\; AS \;|\; SA \;|\; UB\;|\;{\tt a} \;|\; {\tt b}\\
A_1&\to SA\\
U&\to {\tt a}\\
B&\to{\tt b}
\end{align*}
Damit ist die Grammatik in Chomsky Normalform gefunden.
\end{enumerate}

\begin{satz}
Ist $L$ eine kontextfreie Sprache, dann gibt es eine Grammatik,
mit der jedes Wort $w$ mit einem Ableitungsbaum der Tiefe höchstens
$2|w|-1$ abgeleitet werden kann.
\end{satz}

\begin{proof}[Beweis]
Es gibt eine Grammatik in Chomsky Normalform, mit der die Wörter
der Sprache $L$ erzeugt werden können.
Da in Chomsky Normalform nur Regeln der Form $A\to BC$ und $A\to a$
enthalten kann, braucht es genau $|w|-1$ Anwendungen von Regeln der Form
$A\to BC$, um aus der Startvariable einen String aus $|w|$ Zeichen
herzustellen. Weitere $|w|$ Anwendungen von Regeln der Form $A\to a$
wandeln Variablen in Terminalsymbole um. Somit kann ein Wort mit
genau $2|w|-1$ Regelanwendungen produziert werden.
\end{proof}


\subsection{Ein deterministischer Parse-Algorithmus}
Ob ein Wort zu einer regulären Sprache gehört, kann in linearer
Zeit entschieden werden. Dazu erzeugt man einen DEA, der die Sprache
akzeptiert, und testet ein Wort damit.

Für kontextfreie Sprachen gibt es ebenfalls einen deterministischen
Algorithmus, den Cocke-Younger-Kasami Algorithmus. Dazu verwendet
man die Grammatik in Chomsky-Normalform. Der Algorithmus arbeitet
rekursiv um die Frage zu beantworten, ob ein Wort $w$ aus einer
Variablen $A$ der Grammatik $G=(V,\Sigma,R,S)$  abgeleitet
werden kann.

Um das leere Wort zu erzeugen, muss die Regel $S\to\varepsilon$
angewendet werden, falls sie vorhanden ist.

Ein Wort $w$ mit Länge $|w|=1$ kann genau dann aus der Variablen 
$A$ abgeleitet werden, wenn es eine Regel $A\to a$ gibt. 
Es kann höchstens $|\Sigma|$ solche Regeln geben.

Um ein Wort der Länge $|w|>1$ zu erzeugen, muss mindestens eine
Regel der Form
$A\to BC$ verwendet werden. Sie teilt das Wort in in zwei Teile
$w_1$ und $w_2$ mit je geringerer Länge: $w=w_1w_2$ und 
$|w_i|<|w|$. Es gibt $|w|-1$ solche Zerlegungen. Um also zu testen,
ob die Grammatik das Wort $w$ aus der Variablen $A$ ableitet,
muss man also rekursiv alle möglichen
Zerlegungen des Wortes daraufhin testen, ob sie von den Variablen
$B$ bzw.~$C$ erzeugt werden, ob also $B\overset{*}\Rightarrow w_1$
und $C\overset{*}\Rightarrow w_2$ gilt, und dies für jede
Regel $A\to BC\in R$. Es gibt weniger als $|R|$ solche Regeln.

Zur Implementation dieses rekursiven Algorithmus braucht man
also eine Funktion {\tt ableitbar}, die die Frage beantwortet,
ob ein Wort aus einer bestimmten Variable ableitbar ist. Sie
ruft sich für jede Aufteilung des Wortes in zwei Teile
$w_1$ und $w_2$ und für jede Regel $A\to BC$ selbst auf, um
herauszufinden, ob $w_1$ aus $B$ und $w_2$ aus $C$ ableitbar ist.

Der Pseudocode Algorithm~\ref{cyk-algorithm-code} implementiert
diesen Algorithmus.
\begin{algorithm}
\begin{algorithmic}[1]
\STATE {\tt boolean ableitbar(}Variable $V$, Wort $w${\tt ) \{}
\STATE \hskip1em{\tt if ((}$|w| = 0${\tt )} und {\tt (}Regel $V\to\varepsilon$ vorhanden{\tt )) \{}
\STATE \hskip2em {\tt return true; }
\STATE \hskip1em{\tt \}}
\STATE \hskip1em{\tt if ((}$|w| = 1${\tt )} und {\tt (}Regel $V\to w$ vorhanden{\tt ) \{}
\STATE \hskip2em{\tt return true; }
\STATE \hskip1em{\tt \}}
\STATE \hskip1emFür jede Unterteilung $w=w_1w_2$ mit $|w_1| > 0$ und $|w_2| > 0$ {\tt \{}
\STATE \hskip2emFür jede Regel $V\to AB$ {\tt \{}
\STATE \hskip3em{\tt if ((ableitbar(}$A,w_1${\tt ) \&\& (ableitbar(}$B,w_2${\tt )) \{ }
\STATE \hskip4em{\tt return true;}
\STATE \hskip3em{\tt \}}
\STATE \hskip2em{\tt \}}
\STATE \hskip1em{\tt \}}
\STATE \hskip1em{\tt return false;}
\STATE {\tt \}}
\end{algorithmic}
\caption{Algorithmus von Cocke-Younger-Kasami\label{cyk-algorithm-code}}
\end{algorithm}


\begin{satz}[Cocke-Younger-Kasami]
\index{Algorithmus!Cocke-Younger-Kasami}%
\index{Algorithmus!CYK|see{Cocke-Younger-Kasami}}%
\index{Cocke-Younger-Kasami}%
\label{cyk-algorithm}
Es gibt einen deterministischen Algorithmus mit Komplexität
$O(|w|^3)$, welcher entscheidet, ob $w\in L(G)$.
\end{satz}

Das Argument weiter oben erklärt, dass es einen determinisitischen
Algorithmus gibt. Es erklärt aber nicht, warum die Komplexität
nur $O(|w|^3)$ ist. Ähnlich wie man bei einer rekursiven Berechnung
der Fibonacci-Zahlen die Komplexität von $O(2^n)$ auf $O(n)$ reduzieren
kann, indem man bereits berechnet Fibonacci-Zahlen speichert, kann
man auch beim obigen rekursiven Algorithmus die Komplexität wesentlich
reduzieren, indem man bereits geprüfte Ableitungen zwischenspeichert.
Wir verzichten jedoch auf eine detaillierte Durchführung dieses
Beweises.

