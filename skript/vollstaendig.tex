%
% Turing-Vollstaendigkeit
%
% (c) 2011 Prof Dr Andreas Mueller, Hochschule Rapperswil
% $Id$
%
\chapter{Turing-Vollständigkeit\label{chapter-vollstaendigkeit}}
\lhead{Vollständigkeit}
\section{Turing-vollständige Programmiersprachen}
\rhead{Turing-vollständige Programmiersprachen}
Die Turing-Maschine liefert einen wohldefinierten Begriff der
Berechenbarkeit, der auch robust gegenüber milden "Anderungen
der Definition einer Turing-Maschine ist.
Der Aufbau aus einem endlichen Automaten mit zusätzlichem
Speicher und der einfache Kalkül mit Konfigurationen hat
sie ausserdem Beweisen vieler wichtiger Eigenschaften zugänglich
gemacht. Die vorangegangenen Kapitel über Entscheidbarkeit und
Komplexität legen davon eindrücklich Zeugnis ab. Am direkten
Nutzen dieser Theorie kann jedoch immer noch ein gewisser Zweifel
bestehen, da ein moderner Entwickler seine Programme ja nicht
direkt für eine Turing-Maschine schreibt, sondern nur mittelbar,
da er eine Programmiersprache verwendet, deren Code anschliessend
von einem Compiler oder Interpreter übersetzt und von einer realen
Maschine ausgeführt wird.

Der Aufbau der realen Maschine ist sehr
nahe an einer Turing-Maschine, ein Prozessor liest und schreibt
jeweils einzelne
Speicherzellen eines mindestens für praktische Zwecke unendlich
grossen Speichers und ändert bei Verarbeitung der gelesenen
Inhalte seinen eigenen Zustand. Natürlich ist die Menge der
Zustände eines modernen Prozessors sehr gross, nur schon die $n$
Register der Länge $l$ tragen $2^{nl}$ verschiedene Zustände bei,
und jedes andere Zustandsbit verdoppelt die Zustandsmenge nochmals.
Trotzdem ist die Zustandsmenge endlich, und es braucht nicht viel
Fantasie, sich den Prozessor mit seinem Hauptspeicher als Turingmaschine
vorzustellen. Es gibt also kaum Zweifel, dass die Computer-Hardware
zu all dem fähig ist, was ihr in den letzten zwei Kapiteln an
Fähigkeiten zugesprochen wurde.

Die einzige Einschränkung der Fähigkeiten realer Computer gegenüber
Turing-Maschinen ist
die Tatsache, dass reale Computer nur über einen endlichen Speicher
verfügen, während eine Turing-Maschine ein undendlich langes Band
als Speicher verwenden kann. Da jedoch eine endliche Berechnung auch
nur endlich viel Speicher verwenden kann, sind alle auf einer Turing-Maschine
durchführbaren Berechnungen, die man auch tatsächlich durchführen
will, auch von einem realen Computer durchführbar. Für praktische
Zwecke darf man also annehmen, dass die realen Computer echte Turing-Maschinen
sind.

Trotzdem ist nicht sicher, ob die Programmierung in einer übersetzten
oder interpretierten Sprache alle diese Fähigkeiten auch einem
Anwendungsprogrammierer zugänglich macht.
Letztlich äussert sich dies auch darin, dass Computernutzer
für verschiedene Problemstellung auch verschiedene Werkzeuge
verwenden. Wer tabellarische Daten summieren will, wird gerne
zu einer Spreadsheet-Software greifen, aber nicht erwarten, dass er
damit auch einen Näherungsalgorithmus für das Cliquen-Problem wird
programmieren können. Die Tabellenkalkulation definiert ein eingeschränktes,
an das Problem angepasstes Berechnungsmodell, welches aber
höchstwahrscheinlich weniger leistungsfähig ist als die Hardware, auf
der es läuft. Es ist also durchaus möglich und je nach Anwendung auch
zweckmässig, dass ein Anwender nicht die volle Leistung einer
Turing-Maschine zur Verfügung hat.

Damit stellt sich jetzt die Frage, wie man einem Berechnungsmodell und
das heisst letztlich der Sprache, in der der Berechnungsauftrag
formuliert wird, ansehen kann, ob sie gleich mächtig ist wie eine
Turing-Maschine.

\subsection{Programmiersprachen}
Eine Programmiersprache ist zwar eine Sprache im Sinne dieses Skriptes,
für den Programmierer wesentlich ist jedoch die Semantik, die bisher
nicht Bestandteil der Diskussion war. Für ihn ist die Tatsache wichtig,
dass die Semantik der Sprache Berechnungen beschreibt,
wie sie mit einer Turing-Maschine ausgeführt werden können.

\begin{definition}
\index{Programmiersprache}
Eine Sprache $A$ heisst eine {\em Programmiersprache}, wenn es eine Abbildung
\[
c\colon A\to \Sigma^*\colon w\mapsto c(w)
\]
gibt, die einem Wort der Sprache die Beschreibung einer Turing-Maschine
zuordnet. Die Abbildung $c$ heisst {\em Compiler} für die Sprache $A$.
\end{definition}
Die Forderung, dass $c(w)$ die Beschreibung einer Turing-Maschine
sein muss, ist nach obiger Diskussion nicht wesentlich.

\subsection{Interaktion}
Man beachte, dass in dieser Definition einer Programmiersprache kein Platz ist
für Input oder Output während des Programmlaufes.
Das Band der Turing-Maschine, bzw.~sein Inhalt bildet den Input, der Output
kann nach Ende der Berechnung vom Band gelesen werden.
Man könnte dies als Mangel dieses Modells ansehen, in der Tat ist aber
keine Erweiterung nötig, um Interaktion abzubilden.
Interaktionen mit einem Benutzer bestehen immer aus einem Strom von
Ereignissen, die dem Benutzer zufliessen ("Anderungen des Bildschirminhaltes,
Signaltöne) oder die der Benutzer veranlasst (Bewegungen des Maus-Zeigers,
Maus-Klicks, Tastatureingaben). Alle diese Ereignisse kann man sich codiert
auf ein Band geschrieben denken, welches die Turing-Maschine bei Bedarf
liest.

Der Inhalt des Bandes einer Standard-Turing-Maschine kann während des
Programmlaufes nur von der Turing-Maschine selbst verändert werden.
Da sich die Turing-Maschine aber nicht daran erinnern kann, was beim
letzten Besuch eines Feldes dort stand, ist es für eine Turing-Maschine
auch durchaus akzeptabel, wenn der Inhalt eines Feldes von aussen
geändert wird. Natürlich werden damit das Laufzeitverhalten der
Turing-Maschine verändert. Doch in Anbetracht der
Tatsache, dass von einer Turing-Maschine im Allgemeinen nicht einmal
entschieden werden kann, ob sie anhalten wird, ist wohl nicht mehr
viel zu verlieren.

Die Ausgaben eines Programmes sind deterministisch, und was der Benutzer
erreichen will, sowie die Ereignisse, die er einspeisen wird, sind es ebenfalls.
Man kann also im Prinzip im Voraus wissen, was ausgegeben werden wird
und welche Ereignisse ein Benutzer auslösen wird. Schreibt man diese
vorgängig auf das Band, so wie man es auch beim automatisierten Testen
eines Userinterfaces tut, entsteht aus dem interaktiven Programm eines,
welches ohne Zutun des Benutzers zur Laufzeit funktionieren kann.

\subsection{Die universelle Turing-Maschine}
\index{Turing, Alan}
\index{Turing-Maschine!universelle}
In seinem Paper von 1936 hat Alan Turing gezeigt, dass man eine
Turing-Maschine definieren kann,
der man die Beschreibung
$\langle M,w\rangle$
einer Turing-Maschine $M$ und eines Wortes $w$
und die $M$ auf dem Input-Wort $w$ simuliert.
Diese spezielle Turing-Maschine ist also leistungsfähig genug, jede
beliebige andere Turing-Maschine zu simulieren. Sie heisst die {\em universelle
Turing-Maschine}.

Die universelle Turing-Maschine kann die Entscheidung vereinfachen,
ob eine Funktion Turing-berechenbar ist. Statt eine Turing-Maschine
zu beschreiben, die die Funktion berechnet, reicht es, ein Programm
in der Programmiersprache $A$ zu beschreiben, das Programm mit dem
Compiler $c$ zu übersetzen, und die Beschreibung mit der universellen
Turing-Maschine auszuführen.

\index{Church-Turing-Hypothese}
Die Church-Turing-Hypothese besagt, dass sich alles, was man berechnen
kann, auch mit einer Turing-Maschine berechnen lässt. Die universelle
Turing-Maschine zeigt, dass jede berechenbare Funktion von der
universellen Turing-Maschine berechnet werden kann.
Etwas leistungsfähigeres als eine Turing-Maschine gibt es nicht.

\subsection{Turing-Vollständigkeit}
Jede Funktion, die in der Programmiersprache $A$ implementiert werden
kann, ist Turing-berechenbar.
Der Compiler kann
aber durchaus Fähigkeiten unzugänglich machen, die Programmiersprache
$A$ kann dann gewisse Berechnungen, die mit einer Turing-Maschine
möglich wären, nicht formulieren. Besonderes interessant sind daher
die Sprachen, bei denen ein solcher Verlust nicht eintritt.

\begin{definition}
\index{Turing-vollst\ändig}
Eine Programmiersprache heisst Turing-vollständig, wenn sich jede
berechenbare Abbildung in dieser Sprache formulieren lässt.
Zu jeder berechenbaren Abbildung $f\colon\Sigma^*\to \Sigma^*$ gibt
es also ein Programm $w$ so, dass $c(w)$ die Funktion $f$ berechnet.
\end{definition}

Zu einer berechenbaren Abbildung gibt es eine Turing-Maschine, die
sie berechnet, es würde also genügen, wenn man diese Turing-Maschine
von einem in der Sprache $A$ geschriebenen Turing-Maschinen-Simulator
ausführen lassen könnte. Dieser Begriff muss noch etwas klarer gefasst
werden:

\begin{definition}
\index{Turing-Maschinen-Simulator}
Ein Turing-Maschinen-Simulator ist eine Turing-Maschine $S$, die als Input
die Beschreibung $\langle M,w\rangle$ einer Turing-Maschine $M$ und eines
Input-Wortes für $M$ erhält, und die Berechnung durchführt, die $M$ auf $w$
ausführen würde.
Ein Turing-Maschinen-Simulator in der Programmiersprache $A$ ist
ein Wort $s\in A$ so, dass $c(s)$ ein Turing-Maschinen-Simulator ist.
\end{definition}

Damit erhalten wir ein Kriterium für Turing-Vollständigkeit:

\begin{satz}
\label{turingvollstaendigkeitskriterium}
Eine Programmiersprache $A$ ist Turing-vollständig, genau dann
wenn es einen Turing-Maschinen-Simulator in $A$ gibt.
\end{satz}


\subsection{Beispiele}
Die üblichen Programmiersprachen sind alle Turing-vollständig, denn es
ist eine einfache Programmierübung, eines Turing-Maschinen-Simulator
in einer dieser Sprachen zu schreiben. In einigen Programmiersprachen
ist dies jedoch schwieriger als in anderen.

\subsubsection{Javascript}
\index{Javascript}
Fabrice Bellard hat 2011 einen PC-Emulator in Javascript geschrieben, der
leistungsfähig genug ist, Linux zu booten. Auf seiner Website
\url{http://bellard.org/jslinux/} kann man den Emulator im eigenen Browser
starten. Das gebootete Linux enthält auch einen C-Compiler. Da C
Turing-vollständig ist, gibt es einen Turing-Maschinen-Simulator in
C, den man auch auf dieses Linux bringen und mit dem C-Compiler
kompilieren kann. Somit gibt es einen Turing-Maschinen-Simulator in
Javascript, Javascript ist Turing-vollständig.

\subsubsection{XSLT}
\index{XSLT}
XSLT ist eine XML-basierte Sprache, die Transformationen von XML-Dokumenten
zu beschreiben erlaubt. XSLT ist jedoch leistungsfähig, eine Turing-Maschine
zu simulieren. Bob Lyons hat auf seiner Website
\url{http://www.unidex.com/turing/utm.htm} ein XSL-Stylesheet publiziert,
welches einen Simulator implementiert. Als Input verlangt es
ein
XML-Dokument, welches die Beschreibung der Turing-Maschine in einem
zu diesem Zweck definierten XML-Format namens Turing Machine Markup
Language (TMML) enthält. TMML definiert XML-Elemente, die das Alphabet
(\verb+<symbols>+),
die Zustandsmenge $Q$ (\verb+<state>...</state>+)
und die "Ubergangsfunktion $\delta$ in \verb+<mapping>+-Elementen
der Form
\begin{verbatim}
<mapping>
    <from current-state="moveRight1" current-symbol=" " />
    <to next-state="check1" next-symbol=" " movement="left" />
</mapping>
\end{verbatim}
beschreiben. Der initiale Bandinhalt wird als Parameter \verb+tape+
auf der Kommandozeile übergeben.
Das Stylesheet wandelt das TMML Dokument in eine ausführliche
Berechnungsgeschichte um, aus der auch der Bandinhalt am Ende der Berechnung
abzulesen ist. Es beweist somit, dass XSLT einen Turing-Maschinen-Simulator
hat, also Turing-vollständig ist.

\subsubsection{\LaTeX}
\index{LaTeX@\LaTeX}
\index{Knuth, Don}
Don Knuth, der Autor von \TeX, hat sich lange davor gedrückt, seiner
Schriftsatz-Sprache auch eine Turing-vollständige Programmiersprache
zu spendieren. Schliesslich kam er nicht mehr darum herum, und wurde
von Guy Steeles richtigegehend dazu gedrängt, wie er in
\url{http://maps.aanhet.net/maps/pdf/16\_15.pdf}
gesteht.

Dass \TeX Turing-vollständig ist beweist ein Satz von \LaTeX-Macros, den
man auf
\url{https://www.informatik.uni-augsburg.de/en/chairs/swt/ti/staff/mark/projects/turingtex/}
finden kann.
Um ihn zu verwenden, formuliert man die Beschreibung
von Turing-Maschine und initialem Bandinhalt als eine Menge von
\LaTeX-Makros. Ebenso ruft man den Makro \verb+\RunTuringMachine+ auf,
der die Turing-Machine simuliert und die Berechnungsgeschichte im
\TeX-üblichen perfekten Schriftsatz ausgibt.



\section{Kontrollstrukturen und Turing-Vollständigkeit}
\rhead{Kontrollstrukturen}
Das Turing-Vollstandigkeits-Kriterium von Satz
\ref{turingvollstaendigkeitskriterium} verlangt, dass man einen
Turing-Maschinen-Simulator in der gewählten Sprache schreiben muss.
Dies ist in jedem Fall eine nicht triviale Aufgabe.
Daher wäre es nützlich Kriterien zu erhalten, welche einfacher
anzuwenden sind. Einen wesentlichen Einfluss auf die Möglichkeiten,
was sich mit einer Programmiersprache ausdrücken lassen, haben die
Kontrollstrukturen.

\newcommand{\assignment}{\mathbin{\texttt{:=}}}

\subsection{Grundlegende Syntaxelemente%
\label{subsection:grundlegende-syntaxelement}}
In den folgenden Abschnitten werden verschiedene vereinfachte Sprachen
diskutiert, die aber einen gemeinsamen Kern fundamentaler Anweisungen
beinahlten.
In allen Sprachen gibt es nur einen einzigen Datentyp, nämlich
natürliche Zahlen.
Einerseits können Konstanten beliebig grosse natürliche Werte haben,
andererseits lassen sich in Variablen beliebig grosse natürliche Zahlen
speichern.
Dazu sind die folgenden Sytanxelemente notwendig:
\begin{compactitem}
\item Konstanten: {\tt 0}, {\tt 1}, {\tt 2}, \dots
\item Variablen $x_0$, $x_1$, $x_2$,\dots
\item Zuweisung: $\assignment$
\item Trennung von Anweisungen: {\tt ;}
\item Operatoren: {\tt +} und {\tt -}
\end{compactitem}
Die einzige Möglichkeit, den Wert einer Variablen zu ändern ist die
Zuweisung.  Diese ist entweder die Zuweisung einer Konstante als
Wert einer Variable:
\begin{algorithmic}
\STATE $x_i\assignment c$
\end{algorithmic}
oder eine Berechnung mit den beiden vorhandenen Operatoren
\begin{algorithmic}
\STATE $x_i \assignment x_j$ {\tt +} $c$
\STATE $x_i \assignment x_j$ {\tt -} $c$
\end{algorithmic}
Dabei ist das Resultat der Subtraktion als $0$ definiert, wenn
der Minuend kleiner ist als der Subtrahend.

Die verschiedenen Sprachen unterschieden sich in den Kontrollstrukturen
mit denen diese Zuweisungsbefehle miteinander verbunden werden können.

\subsection{LOOP}
\index{LOOP}
Die Programmiersprache
LOOP\footnote{Die in diesem Abschnitt beschriebene
LOOP Sprache darf nicht verwechselt werden mit dem gleichnamigen
Projekt einer objektorientierten parallelen Sprache seit
2001 auf Sourceforge.}
hat als einzige Kontrollstruktur die
Iteration eines Anweisungs-Blocks mit einer festen, innerhalb des
Blocks nicht veränderbaren Anzahl von Durchläufen.

\subsubsection{Syntax}
LOOP verwendet die 
Schlüsselwörter: {\tt LOOP}, {\tt DO}, {\tt END}
Programme werden daraus wie folgt aufgebaut:
\begin{itemize}
\item Das leere Programm $\varepsilon$ ist ein LOOP-Programm,
während der Ausführung tut es nichts.
\item Wertzuweisungen sind LOOP-Programme
\item Sind $P_1$ und $P_2$ LOOP-Programme, dann auch
$P_1{\tt ;}P_2$. Um dieses Programm auszuführen wird zuerst $P_1$
ausgeführt und anschliessend $P_2$.
\item Ist $P$ ein LOOP-Programm, dann ist auch
\begin{algorithmic}
\STATE {\tt LOOP} $x_i$ {\tt DO} $P$ {\tt END}
\end{algorithmic}
ein LOOP-Programm. Die Ausführung wiederholt $P$ so oft, wie der
Wert der Variable $x_i$  zu Beginn angibt.
\end{itemize}
Durch Setzen der Variablen $x_i$ kann einem LOOP-Progamm Input übergeben
werden.
Ein LOOP-Programm definiert also eine Abbildung $\mathbb N^k\to\mathbb N$,
wobei $k$ die Anzahl der Variablen ist, in denen Input zu übergeben ist.

\subsubsection{Beispiel: Summer zweier Variablen}
LOOP kann nur jeweils eine Konstante hinzuaddieren, das genügt aber
bereits, um auch die Summe zweier Variablen zu berechnen. Der folgende
Code berechnet die Summe von $x_1$ und $x_2$ und legt das Resultat in
$x_0$ ab:
\begin{algorithmic}
\STATE $x_0 \assignment x_1$
\STATE {\tt LOOP} $x_2$ {\tt DO}
\STATE{\tt \ \ \ \ }$x_0 \assignment x_0$ {\tt +} $1$
\STATE{\tt END}
\end{algorithmic}

\subsubsection{Beispiel: Produkt zweier Variablen}
\index{Multiplikation}
Die Sprache LOOP ist offenbar relativ primitiv, trotzdem
ist sie leistungsfähig genug, um die Multiplikation von zwei
Zahlen, die in den Variablen $x_1$ und $x_2$ übergeben werden,
zu berechnen:

\begin{algorithmic}
\STATE $x_0 \assignment 0$
\STATE {\tt LOOP} $x_1$ {\tt DO}
\STATE{\tt \ \ \ \ LOOP} $x_2$ {\tt DO}
\STATE{\tt \ \ \ \ \ \ \ \ }$x_0 \assignment x_0$ {\tt +} $1$
\STATE{\tt \ \ \ \ END}
\STATE{\tt END}
\end{algorithmic}

\subsubsection{IF-Anweisung}
In LOOP fehlt eine IF-Anweisung, auf die die wenigsten Programmiersprachen
verzichten. Es ist jedoch leicht, eine solche in LOOP nachzubilden.
Eine Anweisung
\begin{algorithmic}
\STATE {\tt IF} $x = 0$ {\tt THEN } $P$ {\tt END}
\end{algorithmic}
kann unter Verwendung einer zusätzlichen Variable $y$ in LOOP ausgedrückt
werden:
\begin{algorithmic}[1]
\STATE $y \assignment 1${\tt ;}
\STATE {\tt LOOP }$x${\tt\ DO }$y \assignment 0$ {\tt END;}
\STATE {\tt LOOP }$y${\tt\ DO }$P$ {\tt END;}
\end{algorithmic}
Natürlich wird die {\tt LOOP}-Anweisung in Zeile 2 meistens viel öfter
als nötig ausgeführt, aber es stehen hier ja auch nicht Fragen
der Effizienz sonder der prinzipiellen Machbarkeit zur Diskussion.

\subsubsection{LOOP ist nicht Turing-vollständig}
\begin{satz}
LOOP-Programme terminieren immer.
\end{satz}

\begin{proof}[Beweis]
Der Beweis kann mit Induktion über die Schachtelungstiefe
von {\tt LOOP}-Anweisungen geführt werden. Die LOOP-Programme
ohne {\tt LOOP}-Anweisung, also die Programme mit Schachtelungstiefe
$0$ terminieren offensichtlich immer. Ebenso die LOOP-Programme
mit Schachtelungstiefe $1$, da die Anzahl der Schleifendurchläufe
bereits zu Beginn der Schleife festliegt.

Nehmen wir jetzt an wir wüssten bereits, dass jedes LOOP-Programm mit
Schachtelungstiefe $n$ der {\tt LOOP}-Anweisungen immer terminiert.
Ein LOOP-Programm mit Schachtelungstiefe $n+1$ ist dann eine
Abfolge von Teilprogrammen mit Schachtelungstiefe $n$, die nach
Voraussetzung alle terminieren, und {\tt LOOP}-Anweisungen der
Form
\begin{algorithmic}
\STATE{\tt LOOP }$x_i${\tt\ DO }$P${\tt\ END}
\end{algorithmic}
wobei $P$ ein LOOP-Programm mit Schachtelungstiefe $n$ ist, das also
ebenfalls immer terminiert. $P$ wird genau so oft ausgeführt, wie
$x_i$ zu Beginn angibt. Die Laufzeit von $P$ kann dabei jedesmal
anders sein, $P$ wird aber auf jeden Fall terminieren. Damit ist
gezeigt, dass auch alle LOOP-Programme mit Schachtelungstiefe $n+1$
terminieren.
\end{proof}

\begin{satz}
LOOP ist nicht Turing vollständig.
\end{satz}

\begin{proof}[Beweis]
Es gibt Turing-Maschinen, die nicht terminieren. Gäbe es einen
Turing-Maschinen-Simulator in LOOP, dürfte dieser bei der
Simulation einer solchen Turing-Maschine nicht terminieren, im
Widerspruch zur Tatsache, dass LOOP-Programme immer terminieren.
Also kann es keinen Turing-Maschinen-Simulator in LOOP geben.
\end{proof}

\subsection{WHILE}
\index{WHILE}%
WHILE-Programme können zusätzlich zur {\tt LOOP}-Anweisung
eine {\tt WHILE}-Anweisung der Form
\begin{algorithmic}
\STATE{\tt WHILE }$x_i>0${\tt\ DO }$P${\tt\ END}
\end{algorithmic}
Dadurch ist die {\tt LOOP}-Anweisung nicht mehr unbedingt
notwendig, denn
\begin{algorithmic}
\STATE{\tt LOOP }$x${\tt\ DO }$P${\tt\ END}
\end{algorithmic}
kann durch
\begin{algorithmic}
\STATE$y \assignment x$;
\STATE{\tt WHILE }$y>0${\tt\ DO }$P$; $y \assignment y-1${\tt\ END}
\end{algorithmic}
nachgebildet werden.

\subsection{GOTO}
\index{GOTO}
GOTO-Programme bestehen aus einer markierten Folge von Anweisungen
\begin{center}
\begin{tabular}{rl}
$M_1$:&$A_1$\\
$M_2$:&$A_2$\\
$M_3$:&$A_3$\\
$\dots$:&$\dots$\\
$M_k$:&$A_k$
\end{tabular}
\end{center}
Zu den bereits bekannten,
Abschnitt~\ref{subsection:grundlegende-syntaxelement} beschriebenen
Zuweisungen
$x_i \assignment c$ 
und
$x_i \assignment x_j \pm c$ 
kommt bei GOTO eine bedingte Sprunganweisung
\begin{center}
\begin{tabular}{rl}
$M_l$:&{\tt IF\ }$x_i=c${\tt\ THEN GOTO\ }$M_j$
\end{tabular}
\end{center}
Natürlich lässt sich damit auch eine unbedingte Sprunganweisung
implementieren:
\begin{center}
\begin{tabular}{rl}
$M_l$:&$x_i \assignment c$;\\
$M_{l+1}$:&{\tt IF\ }$x_i=c${\tt\ THEN GOTO\ }$M_j$
\end{tabular}
\end{center}
In ähnlicher Weise lassen sich auch andere bedingte Anweisungen
konstruieren, zum Beispiel ein
Konstrukt {\tt IF }\dots{\tt\ THEN }\dots{\tt\ ELSE }\dots{\tt\ END}, welches
einen ganzen Anweisungsblock enthalten kann.

\subsection{"Aquivalenz von WHILE und GOTO}
Die Verwendung eines Sprungbefehles wie GOTO ist in der modernen
Softwareentwicklung verpönt. Sie führe leichter zu Spaghetti-Code,
der kaum mehr wartbar ist. Gewisse Sprachen verbannen daher
GOTO vollständig aus ihrer Syntax, und propagieren dagegen
die Verwendung von `strukturierten' Kontrollstrukturen wie
WHILE. Die Aufregung ist allerdings unnötig: GOTO und WHILE sind äquivalent.


\begin{satz}
Eine Funktion ist genau dann mit einem GOTO-Programm berechenbar,
wenn sie mit einem WHILE-Programm berechenbar ist.
\end{satz}
\begin{proof}[Beweis]
Man braucht nur zu zeigen, dass man ein GOTO-Programm in ein äquivalentes
WHILE-Programm übersetzen kann, und umgekehrt.

Um eine GOTO-Programm zu übersetzen, verwenden wir eine zusätzliche Variable
$z$, die die Funktion des Programm-Zählers übernimmt.
Aus dem GOTO-Programm machen wir dann folgendes WHILE-Programm
\begin{algorithmic}
\STATE $z \assignment 1$
\STATE{\tt WHILE\ }$z>0${\tt\ DO}
\STATE{\tt IF\ }$z=1${\tt\ THEN\ }$A_1'${\tt\ END};
\STATE{\tt IF\ }$z=2${\tt\ THEN\ }$A_2'${\tt\ END};
\STATE{\tt IF\ }$z=3${\tt\ THEN\ }$A_3'${\tt\ END};
\STATE\dots
\STATE{\tt IF\ }$z=k${\tt\ THEN\ }$A_k'${\tt\ END};
\STATE{\tt IF\ }$z=k+1${\tt\ THEN\ }$z \assignment 0${\tt\ END};
\STATE{\tt END}
\end{algorithmic}
Die Anweisung $A_i'$ entsteht aus der Anweisung $A_i$ nach folgenden
Regeln
\begin{itemize}
\item Falls $A_i$ eine Zuweisung ist, wird ihr eine weitere Zuweisung
\begin{algorithmic}
\STATE $z \assignment z+1$
\end{algorithmic}
angehängt.
Dies hat zur Folge, dass nach $A_z'$ als nächste Anweisung
$A_{z+1}$ ausgeführt wird.
\item
Falls $A_i$ eine bedingte Sprunganweisung
\begin{center}
\begin{tabular}{rl}
$M_l$:&{\tt IF\ }$x_i=c${\tt\ THEN GOTO\ }$M_j$
\end{tabular}
\end{center}
ist, wird $A_i'$
\begin{algorithmic}
\STATE{\tt IF\ }$x_i=c${\tt\ THEN\ }$z \assignment j${\tt\ ELSE }$z=z+1$;
\end{algorithmic}
Dies ist zwar keine WHILE-Anweisung, aber es wurde bereits
früher gezeigt, wie man sie in WHILE übersetzen kann.
\end{itemize}
Damit ist gezeigt, dass ein GOTO-Programm in ein äquivalentes WHILE-Programm
mit genau einer WHILE-Schleife übersetzt werden kann.

Umgekehrt zeigen wir, dass jede WHILE-Schleife mit Hilfe von GOTO
implementiert werden kann. Dazu übersetzt man jede WHILE-Schleife
der Form
\begin{algorithmic}
\STATE{\tt WHILE\ }$x_i>0${\tt\ DO }$P${\tt\ END}
\end{algorithmic}
in ein GOTO-Programm-Segment der Form
\begin{algorithmic}[1]
\STATE{\tt IF\ }$x_i=0${\tt\ THEN GOTO }4
\STATE$P$
\STATE{\tt GOTO\ }1
\STATE
\end{algorithmic}
wobei die Zeilennummern durch geeignete Marken ersetzt werden müssen.
Damit haben wir einen Algorithmus spezifiziert, der WHILE-Programme in
GOTO-Programme übersetzen kann.
\end{proof}

\subsection{Turing-Vollständigkeit von WHILE und GOTO}
Da WHILE und GOTO äquivalent sind, braucht die Turing-Vollständigkeit
nur für eine der Sprachen gezeigt zu werden.
Wir skizzieren, wie man eine Turing-Maschine in ein GOTO-Programm
übersetzen kann. Dies genügt, da man nur die universelle
Turing-Maschine zu übersetzen braucht, um damit jede andere
Turing-Maschine ausführen zu können.

\subsubsection{Alphabet, Zustände und Band}
Die Zeichen des Bandalphabetes werden durch natürliche Zahlen
dargestellt.  Wir nehmen an, dass das Bandalphabet $k$ verschiedene Zeichen
umfasst. Das Leerzeichen $\text{\textvisiblespace}$ wird durch die Zahl $0$
dargestellt.

Auch die Zustände der Turing-Maschine werden durch natürliche Zahlen
dargestellt,
die Variable $s$ dient dazu, den aktuellen Zustand zu
speichern.

Der Inhalt des Bandes kann durch eine einzige Variable $b$ dargestellt
werden. Schreibt man die Zahl im System zur Basis $k$, können die
die Zeichen in den einzelnen Felder des Bandes als die Ziffern
der Zahl $b$ interpretiert werden.

Die Kopfposition wird durch eine Zahl $h$ dargestellt. Befindet sich
der Kopf im Feld mit der Nummer $i$, wird $h$ auf den Wert $k^i$
gesetzt.

\subsubsection{Arithmetik}
Alle Komponenten der Turing-Maschine werden mit natürlichen Zahlen
und arithmetischen Operationen dargestellt.
Zwar beherrscht LOOP nur die Addition oder Subtraktion einer Konstanten,
aber durch wiederholte Addition einer $1$ kann damit jede beliebige
Addition oder Subtraktion implementiert werden.

Ebenso können Multiplikation und Division auf wiederholte Addition
zurückgeführt werden.
Im Folgenden nehmen wir daher an, dass die arithmetischen Operationen
zur Verfügung stehen.

\subsubsection{Lesen eines Feldes}
Um den Inhalt eines Feldes zu lesen, muss die Stelle von $b$ an der
aktuellen Kopfposition ermittelt werden.
Dies kann durch die Rechnung
\begin{equation}
z=b / h \mod k
\label{getchar}
\end{equation}
ermittelt werden, wobei $/$ für eine ganzzahlige Division steht.
Beide Operationen können mit einem GOTO-Programm ermittelt werden.

\subsubsection{Löschen eines Feldes}
Das Feld an der Kopfposition kann wie folgt gelöscht werden.
Zunächst ermittelt man mit (\ref{getchar}) den aktuellen Feldinhalt.
Dann berechnet man
\begin{equation}
b' = b - z\cdot h.
\label{clearchar}
\end{equation}
$b'$ enthält an der Stelle der Kopfposition ein $0$.

\subsubsection{Schreiben eines Feldes}
Soll das Feld an der Kopfposition mit dem Zeichen $x$ überschrieben
werden, wird mit (\ref{clearchar}) zuerst das Feld gelöscht.
Anschliessend wird das Feld durch
\[
b'=b+x\cdot h
\]
neu gesetzt.

\subsubsection{Kopfbewegung}
Die Kopfposition wird durch die Zahl $h$ dargestellt.
Da $h$ immer eine Potenz von $k$ ist, und die Nummer des Feldes der
Exponent ist, brauchen wir nur Operationen, die den Exponenten
ändern, also
\[
h'=h/k\qquad\text{bzw.}\qquad h'=h\cdot k
\]

\subsubsection{"Ubergangsfunktion}
Die "Ubergangsfunktion
\[
\delta\colon Q\times \Gamma\to Q\times \Gamma\times\{1, 2\}
\]
ermittelt aus aktuellem Zustand $s$ und
aktuellem Zeichen $z$ den neuen Zustand, das neue Zeichen auf
dem Band und die Kopfbewegung ermittelt. Im Gegensatz zur früheren
Definition verwenden wir jetzt die Zahlen $1$ und $2$ für die
Kopfbewegung L bzw.~R.
Wir schreiben $\delta_i$ für die $i$-te Komponente von $\delta$.
Der folgende GOTO-Pseudocode
beschreibt also ein Programm, welches die Turing-Maschine implementiert
\begin{algorithmic}[1]
\STATE Bestimme das Zeichen $z$ unter der aktuellen Kopfposition $h$
\STATE Lösche das aktuelle Zeichen auf dem Band
\STATE {\tt IF\ }$s=0${\tt\ THEN}
\STATE {\tt \ \ \ \ IF\ }$z=0${\tt\ THEN}
\STATE {\tt \ \ \ \ \ \ \ \ }$s\assignment\delta_1(0,0)$
\STATE {\tt \ \ \ \ \ \ \ \ }$z\assignment\delta_2(0,0)$
\STATE {\tt \ \ \ \ \ \ \ \ }$m\assignment\delta_3(0,0)$
\STATE {\tt \ \ \ \ END}
\STATE {\tt END}
\STATE {\tt IF\ }$s=1${\tt\ THEN}
\STATE {\tt \ \ \ \ }\dots
\STATE {\tt END}
\STATE Zeichen $z$ schreiben
\STATE {\tt IF\ }$m=1${\tt\ THEN }$h\assignment h/k$
\STATE {\tt IF\ }$m=2${\tt\ THEN }$h\assignment h\cdot k$
\STATE \dots
\STATE {\tt GOTO\ }1
\end{algorithmic}
Damit ist gezeigt, dass eine gegebene Turingmaschine in ein
GOTO-Programm übersetzt werden kann. "Ubersetzt man die universelle
Turing-Maschine, erhält man ein GOTO-Programm, welches jede beliebige
Turing-Maschine simulieren kann. Somit ist GOTO und damit auch WHILE
Turing-vollständig.

\subsection{Esoterische Programmiersprachen}
\index{Programmiersprache!esoterische}
Zur Illustration der Tatsache, dass eine sehr primitive Sprache
ausreichen kann, um Turing-Vollständigkeit zu erreichen, wurden
verschiedene esoterische Programmiersprachen erfunden.
Ihre Nützlichkeit liegt darin, ein bestimmtest Konzept der Theorie
möglichst klar hervorzuheben, die Verwendbarkeit für irgend einen
praktischen Zweck ist nicht notwendig, und manchmal explizit unerwünscht.

\subsubsection{Brainfuck}
\index{Brainfuck}
Brainfuck
wurde von Urban Müller 1993 entwickelt mit dem Ziel, dass der
Compiler für diese Sprache möglichst klein sein sollte. In der
Tat ist der kleinste Brainfuck-Compiler für Linux nur 171 Bytes
lang.

Brainfuck basiert auf einem einzelnen Pointer {\tt ptr}, welcher
im Programm inkrementiert oder dekrementiert werden kann.
Jeder Pointer-Wert zeigt auf eine Zelle, deren Inhalt inkrementiert
oder dekrementiert werden kann.
Dies erinnert an die Position des Kopfes einer Turing-Maschine.
Zwei Instruktionen für Eingabe und Ausgabe eines Zeichens
an der Pointer-Position ermöglichen Datenein- und -ausgabe.
Als einzige Kontrollstruktur steht WHILE zur Verfügung. Damit
die Sprache von einem minimalisitischen Compiler kompiliert
werden kann, wird jede Anweisung durch ein einziges Zeichen
dargestellt. Die Befehle sind in der folgenden Tabelle
zusammen mit ihrem C-"Aquivalent zusammengstellt:
\begin{center}
\begin{tabular}{|c|l|}
\hline
Brainfuck&C-"Aquivalent\\
\hline
{\tt >}&\verb/++ptr;/\\
{\tt <}&\verb/--ptr;/\\
{\tt +}&\verb/++*ptr;/\\
{\tt -}&\verb/--*ptr;/\\
{\tt .}&\verb/putchar(*ptr);/\\
{\tt ,}&\verb/*ptr = getchar();/\\
{\tt [}&\verb/while (*ptr) {/\\
{\tt ]}&\verb/}/\\
\hline
\end{tabular}
\end{center}
Mit Hilfe des Pointers lassen sich offenbar beliebige Speicherzellen
adressieren, und diese können durch Wiederholung der Befehle {\tt +}
und {\tt -} auch um konstante Werte vergrössert
oder verkleinert werden. Etwas mehr Arbeit erfordert die Zuweisung
eines Wertes zu einer Variablen. Ist dies jedoch geschafft, kann
man WHILE in Brainfuck übersetzen, und hat damit gezeigt, dass
Brainfuck Turing-vollständig ist.

\subsubsection{Ook}
\index{Ook}
Die Sprache Ook verwendet als syntaktische Element das Wort {\tt Ook} gefolgt
von `{\tt .}', `{\tt !}' oder `{\tt ?}'. Wer beim Lesen eines Ook-Programmes
den Eindruck hat, zum Affen gemacht zu werden, liegt nicht ganz falsch:
Ook ist eine einfache Umcodierung von Brainfuck:
\begin{center}
\begin{tabular}{|c|c|}
\hline
Ook&Brainfuck\\
\hline
{\tt Ook. Ook?}&{\tt >}\\
{\tt Ook? Ook.}&{\tt <}\\
{\tt Ook. Ook.}&{\tt +}\\
{\tt Ook! Ook!}&{\tt -}\\
{\tt Ook! Ook.}&{\tt .}\\
{\tt Ook. Ook!}&{\tt ,}\\
{\tt Ook! Ook?}&{\tt [}\\
{\tt Ook? Ook!}&{\tt ]}\\
\hline
\end{tabular}
\end{center}
Da Brainfuck Turing-vollständig ist, ist auch Ook Turing-vollständig.
